# ğŸš€ Pipeline Pipedrive vers BigQuery - Guide Complet

## ğŸ“‹ Vue d'ensemble

Ce projet utilise **dlt** (data load tool) pour ingÃ©rer automatiquement les donnÃ©es de Pipedrive dans BigQuery. Il inclut des scripts de configuration, de dÃ©ploiement et d'automatisation.

## ğŸ“ Structure du projet

```
Pipedrive/
â”œâ”€â”€ pipedrive/                    # Source dlt Pipedrive
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py
â”‚   â”œâ”€â”€ typing.py
â”‚   â””â”€â”€ helpers/
â”œâ”€â”€ .dlt/                         # Configuration dlt
â”‚   â”œâ”€â”€ config.toml
â”‚   â””â”€â”€ secrets.toml              # âš ï¸ Ã€ configurer
â”œâ”€â”€ pipedrive_pipeline.py         # Script de base
â”œâ”€â”€ pipedrive_main.py             # Script principal avec options
â”œâ”€â”€ configure.py                  # Script de configuration
â”œâ”€â”€ deploy.py                     # Script de dÃ©ploiement
â”œâ”€â”€ run_pipeline.sh              # Script pour cron jobs
â”œâ”€â”€ requirements.txt              # DÃ©pendances Python
â”œâ”€â”€ README.md                    # Documentation principale
â”œâ”€â”€ CRON_SETUP.md               # Guide des tÃ¢ches automatisÃ©es
â””â”€â”€ env.example                 # Exemple de configuration
```

## ğŸ¯ Ressources disponibles (18 au total)

1. **custom_fields_mapping** - Mapping des champs personnalisÃ©s
2. **activities** - ActivitÃ©s et tÃ¢ches
3. **activity_types** - Types d'activitÃ©s
4. **deals** - OpportunitÃ©s de vente
5. **files** - Fichiers attachÃ©s
6. **filters** - Filtres personnalisÃ©s
7. **notes** - Notes
8. **persons** - Contacts individuels
9. **organizations** - Organisations/entreprises
10. **pipelines** - Processus de vente
11. **products** - Produits/services
12. **projects** - Projets
13. **stages** - Ã‰tapes du processus
14. **tasks** - TÃ¢ches
15. **users** - Utilisateurs de la plateforme
16. **deals_participants** - Participants aux deals
17. **deals_flow** - Flux des deals
18. **leads** - Prospects

## âš™ï¸ Configuration rapide

### 1. Installation des dÃ©pendances

```bash
pip3 install -r requirements.txt
```

### 2. Configuration des credentials

**Option A : Script interactif**
```bash
python3 configure.py
```

**Option B : Configuration manuelle**
Ã‰ditez `.dlt/secrets.toml` :

```toml
[sources.pipedrive]
pipedrive_api_key = "votre_token_pipedrive"

[destination.bigquery]
location = "US"

[destination.bigquery.credentials]
project_id = "votre-project-id"
private_key = "-----BEGIN PRIVATE KEY-----\n...\n-----END PRIVATE KEY-----\n"
client_email = "service-account@project.iam.gserviceaccount.com"
```

### 3. Test de configuration

```bash
python3 pipedrive_main.py --mode resources
```

## ğŸš€ Utilisation

### Chargement complet
```bash
python3 pipedrive_main.py --mode all
```

### Chargement sÃ©lectif
```bash
python3 pipedrive_main.py --mode selected --resources deals persons products
```

### Chargement incrÃ©mental (7 derniers jours)
```bash
python3 pipedrive_main.py --mode incremental
```

### Chargement incrÃ©mental depuis une date
```bash
python3 pipedrive_main.py --mode incremental --since 2023-03-01
```

## ğŸ”„ Automatisation

### TÃ¢ches cron

**Chargement quotidien Ã  6h :**
```bash
0 6 * * * /Users/yacinekabeche/Desktop/Vibe\ codings/Pipedrive/run_pipeline.sh incremental
```

**Chargement complet hebdomadaire :**
```bash
0 2 * * 0 /Users/yacinekabeche/Desktop/Vibe\ codings/Pipedrive/run_pipeline.sh all
```

### Script de dÃ©ploiement
```bash
python3 deploy.py
```

## ğŸ“Š Monitoring

### VÃ©rifier les logs
```bash
# Logs rÃ©cents
ls -la logs/

# Suivre les logs en temps rÃ©el
tail -f logs/pipedrive_*.log
```

### VÃ©rifier les donnÃ©es dans BigQuery
```sql
-- Voir les tables crÃ©Ã©es
SELECT table_name 
FROM `votre-project.pipedrive_data.INFORMATION_SCHEMA.TABLES`

-- Exemple de requÃªte sur les deals
SELECT * 
FROM `votre-project.pipedrive_data.deals` 
LIMIT 10
```

## ğŸ› ï¸ DÃ©pannage

### Erreurs courantes

1. **"Placeholder value encountered"**
   - Solution : Configurez vos credentials dans `.dlt/secrets.toml`

2. **"Authentication failed"**
   - Solution : VÃ©rifiez votre token Pipedrive et vos credentials BigQuery

3. **"Permission denied"**
   - Solution : VÃ©rifiez les permissions du service account BigQuery

### Commandes de diagnostic

```bash
# Tester la connexion Pipedrive
python3 -c "from pipedrive import pipedrive_source; print('OK')"

# Tester la connexion BigQuery
python3 -c "import dlt; dlt.pipeline('test', 'bigquery', 'test')"

# Voir les informations du pipeline
python3 pipedrive_main.py --mode info
```

## ğŸ“ˆ Optimisations

### Chargement incrÃ©mental
- Utilisez le mode `incremental` pour les chargements rÃ©guliers
- Le chargement complet est recommandÃ© seulement pour l'initialisation

### SÃ©lection de ressources
- Chargez seulement les ressources nÃ©cessaires avec `--resources`
- Toujours inclure `custom_fields_mapping` pour la traduction des champs

### Performance BigQuery
- Configurez la localisation appropriÃ©e dans `secrets.toml`
- Utilisez des datasets sÃ©parÃ©s pour diffÃ©rents environnements

## ğŸ” SÃ©curitÃ©

- âš ï¸ **Ne jamais commiter** le fichier `.dlt/secrets.toml`
- Utilisez des service accounts avec des permissions minimales
- Configurez la rotation des tokens rÃ©guliÃ¨rement
- Surveillez les accÃ¨s aux donnÃ©es sensibles

## ğŸ“ Support

- Documentation dlt : https://dlthub.com/docs
- Source Pipedrive : https://dlthub.com/docs/dlt-ecosystem/verified-sources/pipedrive
- CommunautÃ© Slack : https://dlthub.com/slack

---

**ğŸ‰ Votre pipeline Pipedrive vers BigQuery est prÃªt !**

Commencez par configurer vos credentials, puis exÃ©cutez votre premier chargement.

