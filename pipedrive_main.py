#!/usr/bin/env python3
"""
Pipeline Pipedrive vers BigQuery avec dlt
Script principal pour l'ingestion des donnÃ©es
"""

import dlt
import argparse
from datetime import datetime, timedelta
from pipedrive import pipedrive_source


def load_all_data(pipeline_name="pipedrive", dataset_name="pipedrive_data"):
    """Charge toutes les donnÃ©es Pipedrive"""
    print("ğŸ”„ Chargement de toutes les donnÃ©es Pipedrive...")
    
    pipeline = dlt.pipeline(
        pipeline_name=pipeline_name,
        destination='bigquery',
        dataset_name=dataset_name
    )
    
    load_info = pipeline.run(pipedrive_source())
    print("âœ… Chargement terminÃ©!")
    print(load_info)
    return load_info


def load_selected_resources(resources, pipeline_name="pipedrive", dataset_name="pipedrive_data"):
    """Charge seulement les ressources sÃ©lectionnÃ©es"""
    print(f"ğŸ”„ Chargement des ressources: {', '.join(resources)}")
    
    pipeline = dlt.pipeline(
        pipeline_name=pipeline_name,
        destination='bigquery',
        dataset_name=dataset_name
    )
    
    # Toujours inclure custom_fields_mapping pour la traduction des champs
    if "custom_fields_mapping" not in resources:
        resources.append("custom_fields_mapping")
    
    source = pipedrive_source().with_resources(*resources)
    load_info = pipeline.run(source)
    print("âœ… Chargement terminÃ©!")
    print(load_info)
    return load_info


def load_incremental(since_date, resources=None, pipeline_name="pipedrive", dataset_name="pipedrive_data"):
    """Charge les donnÃ©es de maniÃ¨re incrÃ©mentale depuis une date donnÃ©e"""
    print(f"ğŸ”„ Chargement incrÃ©mental depuis {since_date}...")
    
    pipeline = dlt.pipeline(
        pipeline_name=pipeline_name,
        destination='bigquery',
        dataset_name=dataset_name
    )
    
    if resources:
        # Charger seulement les ressources spÃ©cifiÃ©es
        if "custom_fields_mapping" not in resources:
            resources.append("custom_fields_mapping")
        source = pipedrive_source(since_timestamp=since_date).with_resources(*resources)
    else:
        # Charger toutes les ressources
        source = pipedrive_source(since_timestamp=since_date)
    
    load_info = pipeline.run(source)
    print("âœ… Chargement incrÃ©mental terminÃ©!")
    print(load_info)
    return load_info


def show_available_resources():
    """Affiche les ressources disponibles"""
    print("ğŸ“‹ Ressources disponibles dans Pipedrive:")
    
    source = pipedrive_source()
    resources = list(source.resources.keys())
    
    for i, resource in enumerate(resources, 1):
        print(f"{i:2d}. {resource}")
    
    print(f"\nTotal: {len(resources)} ressources")
    return resources


def get_pipeline_info(pipeline_name="pipedrive"):
    """Affiche les informations du pipeline"""
    try:
        pipeline = dlt.pipeline(pipeline_name=pipeline_name)
        print(f"ğŸ“Š Informations du pipeline '{pipeline_name}':")
        print(f"   Destination: {pipeline.destination}")
        print(f"   Dataset: {pipeline.dataset_name}")
        print(f"   DerniÃ¨re exÃ©cution: {pipeline.last_trace}")
    except Exception as e:
        print(f"âŒ Erreur lors de la rÃ©cupÃ©ration des infos: {e}")


def main():
    parser = argparse.ArgumentParser(description="Pipeline Pipedrive vers BigQuery")
    parser.add_argument("--mode", choices=["all", "selected", "incremental", "info", "resources"], 
                       default="all", help="Mode d'exÃ©cution")
    parser.add_argument("--resources", nargs="+", 
                       help="Ressources Ã  charger (pour mode 'selected')")
    parser.add_argument("--since", 
                       help="Date de dÃ©but pour le chargement incrÃ©mental (format: YYYY-MM-DD)")
    parser.add_argument("--pipeline-name", default="pipedrive",
                       help="Nom du pipeline")
    parser.add_argument("--dataset-name", default="pipedrive_data",
                       help="Nom du dataset BigQuery")
    
    args = parser.parse_args()
    
    print("ğŸš€ Pipeline Pipedrive vers BigQuery")
    print("=" * 40)
    
    try:
        if args.mode == "all":
            load_all_data(args.pipeline_name, args.dataset_name)
            
        elif args.mode == "selected":
            if not args.resources:
                print("âŒ Veuillez spÃ©cifier les ressources avec --resources")
                print("Exemple: --resources deals persons products")
                return
            load_selected_resources(args.resources, args.pipeline_name, args.dataset_name)
            
        elif args.mode == "incremental":
            if not args.since:
                # Par dÃ©faut, charger depuis il y a 7 jours
                since_date = (datetime.now() - timedelta(days=7)).strftime("%Y-%m-%d %H:%M:%SZ")
                print(f"ğŸ“… Aucune date spÃ©cifiÃ©e, utilisation de la date par dÃ©faut: {since_date}")
            else:
                since_date = f"{args.since} 00:00:00Z"
            
            load_incremental(since_date, args.resources, args.pipeline_name, args.dataset_name)
            
        elif args.mode == "resources":
            show_available_resources()
            
        elif args.mode == "info":
            get_pipeline_info(args.pipeline_name)
            
    except Exception as e:
        print(f"âŒ Erreur lors de l'exÃ©cution: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())

